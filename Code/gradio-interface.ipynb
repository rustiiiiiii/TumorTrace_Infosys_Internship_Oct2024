{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e7b93d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:24.181450Z",
     "iopub.status.busy": "2024-11-21T15:34:24.180976Z",
     "iopub.status.idle": "2024-11-21T15:34:42.715121Z",
     "shell.execute_reply": "2024-11-21T15:34:42.713489Z"
    },
    "papermill": {
     "duration": 18.542501,
     "end_time": "2024-11-21T15:34:42.717440",
     "exception": false,
     "start_time": "2024-11-21T15:34:24.174939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\r\n",
      "  Downloading gradio-5.6.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (22.1.0)\r\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.4.0)\r\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\r\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\r\n",
      "Collecting ffmpy (from gradio)\r\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting gradio-client==1.4.3 (from gradio)\r\n",
      "  Downloading gradio_client-1.4.3-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Requirement already satisfied: httpx>=0.24.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.27.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\r\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.1.4)\r\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.1.5)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (1.26.4)\r\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (3.10.4)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from gradio) (21.3)\r\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.2.3)\r\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (10.3.0)\r\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (2.9.2)\r\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio) (0.25.1)\r\n",
      "Collecting python-multipart==0.0.12 (from gradio)\r\n",
      "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\r\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (6.0.2)\r\n",
      "Collecting ruff>=0.2.2 (from gradio)\r\n",
      "  Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\r\n",
      "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\r\n",
      "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Collecting semantic-version~=2.0 (from gradio)\r\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\r\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\r\n",
      "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Collecting tomlkit==0.12.0 (from gradio)\r\n",
      "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.12.3)\r\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (4.12.2)\r\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio) (0.30.1)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.4.3->gradio) (2024.6.1)\r\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio-client==1.4.3->gradio) (12.0)\r\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\r\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\r\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.5)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (3.15.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->gradio) (3.1.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.23.4)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.25.1->gradio) (1.26.18)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\r\n",
      "Downloading gradio-5.6.0-py3-none-any.whl (57.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gradio_client-1.4.3-py3-none-any.whl (320 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\r\n",
      "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\r\n",
      "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\r\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\r\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\r\n",
      "Installing collected packages: tomlkit, semantic-version, ruff, python-multipart, ffmpy, starlette, safehttpx, gradio-client, fastapi, gradio\r\n",
      "  Attempting uninstall: tomlkit\r\n",
      "    Found existing installation: tomlkit 0.13.2\r\n",
      "    Uninstalling tomlkit-0.13.2:\r\n",
      "      Successfully uninstalled tomlkit-0.13.2\r\n",
      "  Attempting uninstall: python-multipart\r\n",
      "    Found existing installation: python-multipart 0.0.9\r\n",
      "    Uninstalling python-multipart-0.0.9:\r\n",
      "      Successfully uninstalled python-multipart-0.0.9\r\n",
      "  Attempting uninstall: starlette\r\n",
      "    Found existing installation: starlette 0.37.2\r\n",
      "    Uninstalling starlette-0.37.2:\r\n",
      "      Successfully uninstalled starlette-0.37.2\r\n",
      "  Attempting uninstall: fastapi\r\n",
      "    Found existing installation: fastapi 0.111.0\r\n",
      "    Uninstalling fastapi-0.111.0:\r\n",
      "      Successfully uninstalled fastapi-0.111.0\r\n",
      "Successfully installed fastapi-0.115.5 ffmpy-0.4.0 gradio-5.6.0 gradio-client-1.4.3 python-multipart-0.0.12 ruff-0.7.4 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.3 tomlkit-0.12.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f263bd8",
   "metadata": {
    "papermill": {
     "duration": 0.00718,
     "end_time": "2024-11-21T15:34:42.731974",
     "exception": false,
     "start_time": "2024-11-21T15:34:42.724794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading all the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b28e4",
   "metadata": {
    "papermill": {
     "duration": 0.006785,
     "end_time": "2024-11-21T15:34:42.745716",
     "exception": false,
     "start_time": "2024-11-21T15:34:42.738931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dc6c1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:42.761679Z",
     "iopub.status.busy": "2024-11-21T15:34:42.761226Z",
     "iopub.status.idle": "2024-11-21T15:34:47.531641Z",
     "shell.execute_reply": "2024-11-21T15:34:47.530271Z"
    },
    "papermill": {
     "duration": 4.781514,
     "end_time": "2024-11-21T15:34:47.534242",
     "exception": false,
     "start_time": "2024-11-21T15:34:42.752728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "model_name = 'vgg16'\n",
    "#Customvgg16 class inherit from nn.Module\n",
    "class CustomVGG16(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(CustomVGG16, self).__init__()\n",
    "\n",
    "        # Loading pre-trained VGG16 model from tourchvision.models\n",
    "        vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "        # Extracting the features and avgpool layers frm pretrainedmodel\n",
    "        self.features = vgg16.features\n",
    "        self.avgpool = vgg16.avgpool\n",
    "\n",
    "        # Define a new classifier nm.Sequential\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096), #input and output\n",
    "            nn.ReLU(inplace=True), #for activation\n",
    "            nn.Dropout(), #for regularization\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.features(x) # Passing the input through the features layer\n",
    "        x = self.avgpool(x) # Using the avgpool layer\n",
    "        x = torch.flatten(x, 1) # Reshaping the output to a 2D tensor\n",
    "        x = self.classifier(x) # Passing the reshaped output to the custom classifier\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f74c9f",
   "metadata": {
    "papermill": {
     "duration": 0.006645,
     "end_time": "2024-11-21T15:34:47.548767",
     "exception": false,
     "start_time": "2024-11-21T15:34:47.542122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Resnet18 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59b53c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:47.567345Z",
     "iopub.status.busy": "2024-11-21T15:34:47.566785Z",
     "iopub.status.idle": "2024-11-21T15:34:47.575793Z",
     "shell.execute_reply": "2024-11-21T15:34:47.574747Z"
    },
    "papermill": {
     "duration": 0.022158,
     "end_time": "2024-11-21T15:34:47.577899",
     "exception": false,
     "start_time": "2024-11-21T15:34:47.555741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resnet18(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Resnet18, self).__init__()\n",
    "\n",
    "        model_resnet18 = models.resnet18(pretrained=True)\n",
    "\n",
    "        self.conv1 = model_resnet18.conv1  # convolutional function\n",
    "        self.bn1 = model_resnet18.bn1  # batch normalization\n",
    "        self.relu = model_resnet18.relu  # relu is your activation function.\n",
    "        self.maxpool = model_resnet18.maxpool  # maxpool is basically taking the biggest value per sub-matrix\n",
    "\n",
    "        self.layer1 = model_resnet18.layer1\n",
    "        self.layer2 = model_resnet18.layer2\n",
    "        self.layer3 = model_resnet18.layer3\n",
    "        self.layer4 = model_resnet18.layer4  # these layers are use for deepening the layers in the architecture which will increase\n",
    "\n",
    "        self.avgpool = model_resnet18.avgpool\n",
    "        self._features = model_resnet18.fc.in_features\n",
    "\n",
    "        self.fc = nn.Linear(self._features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83551eda",
   "metadata": {
    "papermill": {
     "duration": 0.006631,
     "end_time": "2024-11-21T15:34:47.591422",
     "exception": false,
     "start_time": "2024-11-21T15:34:47.584791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### restnet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd55e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:47.606656Z",
     "iopub.status.busy": "2024-11-21T15:34:47.606285Z",
     "iopub.status.idle": "2024-11-21T15:34:47.614694Z",
     "shell.execute_reply": "2024-11-21T15:34:47.613463Z"
    },
    "papermill": {
     "duration": 0.018844,
     "end_time": "2024-11-21T15:34:47.617081",
     "exception": false,
     "start_time": "2024-11-21T15:34:47.598237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Resnet50(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Resnet50, self).__init__()\n",
    "\n",
    "        model_resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "        self.conv1 = model_resnet50.conv1\n",
    "        self.bn1 = model_resnet50.bn1\n",
    "        self.relu = model_resnet50.relu\n",
    "        self.maxpool = model_resnet50.maxpool\n",
    "\n",
    "        self.layer1 = model_resnet50.layer1\n",
    "        self.layer2 = model_resnet50.layer2\n",
    "        self.layer3 = model_resnet50.layer3\n",
    "        self.layer4 = model_resnet50.layer4\n",
    "\n",
    "        self.avgpool = model_resnet50.avgpool\n",
    "        self._features = model_resnet50.fc.in_features\n",
    "\n",
    "        self.fc = nn.Linear(self._features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b128eb",
   "metadata": {
    "papermill": {
     "duration": 0.006649,
     "end_time": "2024-11-21T15:34:47.631025",
     "exception": false,
     "start_time": "2024-11-21T15:34:47.624376",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading all the models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7810a13b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:47.646386Z",
     "iopub.status.busy": "2024-11-21T15:34:47.645982Z",
     "iopub.status.idle": "2024-11-21T15:34:58.956805Z",
     "shell.execute_reply": "2024-11-21T15:34:58.955571Z"
    },
    "papermill": {
     "duration": 11.321437,
     "end_time": "2024-11-21T15:34:58.959243",
     "exception": false,
     "start_time": "2024-11-21T15:34:47.637806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:03<00:00, 181MB/s]\n",
      "/tmp/ipykernel_17/92212320.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vgg16_model.load_state_dict(torch.load(vgg16_path, map_location = torch.device('cpu')))\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 174MB/s]\n",
      "/tmp/ipykernel_17/92212320.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet18_model.load_state_dict(torch.load(resnet18_path, map_location=torch.device('cpu')))\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 195MB/s]\n",
      "/tmp/ipykernel_17/92212320.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  resnet50_model.load_state_dict(torch.load(resnet50_path, map_location=torch.device('cpu')))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Resnet50(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16_path = '/kaggle/input/tumor-trace-models/kaggle/VGG16_Model/vgg16_best.pth'\n",
    "resnet18_path = '/kaggle/input/tumor-trace-models/kaggle/Resnet18_Model/resnet18_best.pth'\n",
    "resnet50_path = '/kaggle/input/tumor-trace-models/kaggle/Resnet50_Model/resnet50_best.pth'\n",
    "\n",
    "vgg16_model = CustomVGG16(num_classes=2)\n",
    "vgg16_model.load_state_dict(torch.load(vgg16_path, map_location = torch.device('cpu')))\n",
    "vgg16_model.eval()\n",
    "\n",
    "\n",
    "resnet18_model = Resnet18(num_classes=2)\n",
    "resnet18_model.load_state_dict(torch.load(resnet18_path, map_location=torch.device('cpu')))\n",
    "resnet18_model.eval()\n",
    "\n",
    "resnet50_model = Resnet50(num_classes=2)\n",
    "resnet50_model.load_state_dict(torch.load(resnet50_path, map_location=torch.device('cpu')))\n",
    "resnet50_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa98346e",
   "metadata": {
    "papermill": {
     "duration": 0.009682,
     "end_time": "2024-11-21T15:34:58.979465",
     "exception": false,
     "start_time": "2024-11-21T15:34:58.969783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Defining the Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31d24ea6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:59.002437Z",
     "iopub.status.busy": "2024-11-21T15:34:59.002008Z",
     "iopub.status.idle": "2024-11-21T15:34:59.008052Z",
     "shell.execute_reply": "2024-11-21T15:34:59.006870Z"
    },
    "papermill": {
     "duration": 0.020379,
     "end_time": "2024-11-21T15:34:59.010240",
     "exception": false,
     "start_time": "2024-11-21T15:34:58.989861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Preprocessing the input image to match your modelss' requirements.\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79152af",
   "metadata": {
    "papermill": {
     "duration": 0.009814,
     "end_time": "2024-11-21T15:34:59.030277",
     "exception": false,
     "start_time": "2024-11-21T15:34:59.020463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5340d7df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:59.052461Z",
     "iopub.status.busy": "2024-11-21T15:34:59.052036Z",
     "iopub.status.idle": "2024-11-21T15:34:59.059355Z",
     "shell.execute_reply": "2024-11-21T15:34:59.058131Z"
    },
    "papermill": {
     "duration": 0.021128,
     "end_time": "2024-11-21T15:34:59.061569",
     "exception": false,
     "start_time": "2024-11-21T15:34:59.040441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(model_name, image):\n",
    "    #preprocessing the image\n",
    "    #adds a new dimension at the 0th position (i.e., the first position).\n",
    "    img = preprocess(image).unsqueeze(0) # This sets the batch size to 1\n",
    "\n",
    "    # Select the model\n",
    "    if model_name == \"VGG16\":\n",
    "        model = vgg16_model\n",
    "    elif model_name == \"ResNet18\":\n",
    "        model = resnet18_model\n",
    "    elif model_name == \"ResNet50\":\n",
    "        model = resnet50_model\n",
    "    else:\n",
    "        return \"Invalid model name\"\n",
    "\n",
    "    \n",
    "    # Get the model's prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get class index\n",
    "    \n",
    "    # Define class labels\n",
    "    classes = [\"benign\", \"malignant\"]\n",
    "    return classes[predicted.item()]  # Return the predicted label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e16edd",
   "metadata": {
    "papermill": {
     "duration": 0.010255,
     "end_time": "2024-11-21T15:34:59.086852",
     "exception": false,
     "start_time": "2024-11-21T15:34:59.076597",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79e05333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-21T15:34:59.110013Z",
     "iopub.status.busy": "2024-11-21T15:34:59.109627Z",
     "iopub.status.idle": "2024-11-21T15:35:07.695806Z",
     "shell.execute_reply": "2024-11-21T15:35:07.694735Z"
    },
    "papermill": {
     "duration": 8.601296,
     "end_time": "2024-11-21T15:35:07.698464",
     "exception": false,
     "start_time": "2024-11-21T15:34:59.097168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "Kaggle notebooks require sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
      "\n",
      "* Running on public URL: https://6346497eacbf9784b1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://6346497eacbf9784b1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Create the interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict,  # Function to call for prediction\n",
    "    inputs=[\n",
    "        gr.Dropdown(choices=[\"VGG16\", \"ResNet18\", \"ResNet50\"], label=\"Select Model\"),  # Dropdown for model selection\n",
    "        gr.Image(type=\"pil\")  # Input: Upload an image\n",
    "    ],\n",
    "    outputs=\"label\",  # Output: Display the label (benign/malignant)\n",
    "    title=\"Tumor Classification\",\n",
    "    description=\"Select a model and upload an MRI image to classify it as benign or malignant.\"\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6135770,
     "sourceId": 9972901,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.841557,
   "end_time": "2024-11-21T15:35:10.329569",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-21T15:34:21.488012",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
