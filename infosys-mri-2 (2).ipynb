{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":9895055,"sourceType":"datasetVersion","datasetId":6077684},{"sourceId":9996867,"sourceType":"datasetVersion","datasetId":6152878}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### from google.colab import drive\n\n#drive.mount('/content/drive')","metadata":{"id":"GaxmYXRodBqV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"87b6b73c-9b27-4b17-c047-88a424a94a3e","execution":{"iopub.status.busy":"2024-11-15T13:02:46.744009Z","iopub.execute_input":"2024-11-15T13:02:46.744381Z","iopub.status.idle":"2024-11-15T13:02:46.748604Z","shell.execute_reply.started":"2024-11-15T13:02:46.744348Z","shell.execute_reply":"2024-11-15T13:02:46.747481Z"}}},{"cell_type":"code","source":"import os\n\nimport matplotlib.pyplot as plt\n\nimport numpy as np\n\nfrom torchvision import datasets, transforms\n\nfrom torch.utils.data import DataLoader\n\nimport torchvision\n\n\n\n\n\n# Path to the dataset in Google Drive\n\ndata_dir = '/kaggle/input/infosys-mri-dataset'\n\n\n\n# data augmentation techniques\n\ndata_transforms = {\n\n    'train': transforms.Compose([\n\n        transforms.RandomHorizontalFlip(),    # flip horizontally\n\n        transforms.RandomVerticalFlip(),      # flip vertically\n\n        transforms.RandomRotation(20),        # rotation up to 20 degrees\n\n        transforms.RandomResizedCrop(224),    # crop and resize to 224x224\n\n        transforms.ColorJitter(brightness=0.1, contrast=0.1),  # Adjust brightness/contrast\n\n        transforms.ToTensor(),               # Convert images to PyTorch tensors\n\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize using ImageNet mean and std\n\n\n\n\n\n    ]),\n\n    'val': transforms.Compose([\n\n        transforms.Resize(224),               # Resize validation images to a fixed size\n\n        transforms.ToTensor()                 # Convert images to PyTorch tensors\n\n    ]),\n\n    'test':transforms.Compose([\n\n        transforms.Resize(224),\n\n        transforms.ToTensor()\n\n    ])\n\n\n\n}\n\n\n\n# Load the dataset\n\nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), transform=data_transforms[x])\n\n                  for x in ['train', 'val','test']}\n\n\n\n# Create data loaders\n\ndataloaders = {x: DataLoader(image_datasets[x], batch_size=32, shuffle=True)\n\n               for x in ['train', 'val','test']}\n\n\n\n# Get class names\n\nclass_names = image_datasets['train'].classes\n\nprint(f\"Classes: {class_names}\")  # Should print: ['benign', 'malignant']\n\n\n\n# Count the number of images in each class for train and val datasets\n\ndef count_class_distribution(dataset):\n\n    benign_count = 0\n\n    malignant_count = 0\n\n    for _, label in dataset.samples:\n\n        if label == 0:\n\n            benign_count += 1\n\n        else:\n\n            malignant_count += 1\n\n    return benign_count, malignant_count\n\n\n\n# Count distribution in training and validation sets\n\ntrain_benign, train_malignant = count_class_distribution(image_datasets['train'])\n\nval_benign, val_malignant = count_class_distribution(image_datasets['val'])\n\ntest_benign, test_malignant = count_class_distribution(image_datasets['test'])\n\n\n\nprint(f\"Training set - Benign: {train_benign}, Malignant: {train_malignant}\")\n\nprint(f\"Validation set - Benign: {val_benign}, Malignant: {val_malignant}\")\n\nprint(f\"Validation set - Benign: {test_benign}, Malignant: {test_malignant}\")\n","metadata":{"id":"tAHhT_dld0hS","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4b18b88c-6297-41e5-a4a2-43f382828d7d","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nfrom skimage.feature import hog\n\nfrom skimage import exposure\n\n\n\n# Load the image\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')  # Convert to grayscale\n\n\n\n# Resize the image to 224x224\n\nimage = image.resize((224, 224))\n\n\n\n# Convert image to a NumPy array\n\nimage_np = np.array(image)\n\n\n\n# Plot the original image, HOG image, and histogram of pixel values\n\nplt.figure(figsize=(18, 6))\n\n\n\n# Display the original grayscale image\n\nplt.subplot(1, 2, 1)\n\nplt.imshow(image_np, cmap='gray')\n\nplt.title('Original Grayscale Image')\n\nplt.axis('off')\n\n\n\n\n\n# Plot the histogram of pixel values (0-255)\n\nplt.subplot(1, 2,2)\n\nplt.hist(image_np.ravel(), bins=256, range=(0, 255), color='black', alpha=0.7)\n\nplt.title('Histogram of Pixel Values (0-255)')\n\nplt.xlabel('Pixel Value (0-255)')\n\nplt.ylabel('Frequency')\n\n\n\nplt.tight_layout()\n\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":602},"id":"VTFb2wAbeq7C","outputId":"87d72b6b-de8e-4774-f5ad-b5eb3df618c4","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nfrom skimage.feature import hog\n\nfrom skimage import exposure\n\n\n\n# Load the image\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')  # Convert to grayscale\n\nimage = image.resize((224, 224))\n\nimage_np = np.array(image)\n\n\n\n# Perform HOG feature extraction\n\nhog_features, hog_image = hog(image_np, orientations=8, pixels_per_cell=(16, 16),\n\n                              cells_per_block=(1, 1), visualize=True, channel_axis=None)\n\n\n\n# Rescale HOG image for better visualization\n\nhog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n\n\n\n# Plot the original and HOG images\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\n\nplt.imshow(image_np, cmap='gray')\n\nplt.title('Original Grayscale Image')\n\n\n\nplt.subplot(1, 2, 2)\n\nplt.imshow(hog_image_rescaled, cmap='gray')\n\nplt.title('HOG Features')\n\n\n\nplt.show()\n\n\n\nprint(\"Image Array:\")\n\nprint(image_np)\n\nprint(\"HOG Features Shape:\", hog_features.shape)\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":669},"id":"3MMlHDePejdn","outputId":"d818c945-c597-4382-b6aa-968f89bb9f93","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\nfrom numba import prange\n\n\n\n# Load the image\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')  # Convert to grayscale\n\nimage = image.resize((224, 224))\n\nimage_np = np.array(image)\n\n\n\n# Sobel kernels\n\nsobel_x = np.array([[-1, 0, 1],\n\n                    [-2, 0, 2],\n\n                    [-1, 0, 1]])\n\n\n\nsobel_y = np.array([[-1, -2, -1],\n\n                    [0, 0, 0],\n\n                    [1, 2, 1]])\n\n\n\n# Function to perform convolution using the kernel\n\ndef convolve(x, h):\n\n    xh, xw = x.shape\n\n    hh, hw = h.shape\n\n    # Kernel radius\n\n    rh, rw = np.array(h.shape)//2\n\n    # Init output\n\n    output = np.zeros(x.shape)\n\n    for n1 in prange(rh, xh-rh):\n\n        for n2 in prange(rw, xw-rw):\n\n            value = 0\n\n            for k1 in prange(hh):\n\n                for k2 in prange(hw):\n\n                    value += h[k1, k2]*x[n1 + k1 - rh, n2 + k2 - rw]\n\n            output[n1, n2] = value\n\n    return output\n\n\n\n# Apply convolution using Sobel X and Y kernels\n\ngradient_x = convolve(image_np, sobel_x)\n\ngradient_y = convolve(image_np, sobel_y)\n\n\n\n# Compute the gradient magnitude\n\ngradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n\n\n\n# Normalize the result for visualization (to range 0-1)\n\ngradient_magnitude = (gradient_magnitude - gradient_magnitude.min()) / (gradient_magnitude.max() - gradient_magnitude.min())\n\n\n\n# Display the original and gradient magnitude images\n\nplt.figure(figsize=(12, 6))\n\nplt.subplot(1, 2, 1)\n\nplt.title('Original Image')\n\nplt.imshow(image_np, cmap='gray')\n\nplt.axis('off')\n\n\n\nplt.subplot(1, 2, 2)\n\nplt.title('Gradient Magnitude: Sobel operator')\n\nplt.imshow(gradient_magnitude, cmap='gray')\n\nplt.axis('off')\n\n\n\nplt.show()\n","metadata":{"id":"S3mWw_7CvULu","colab":{"base_uri":"https://localhost:8080/","height":482},"outputId":"aef248c5-f224-4ae7-edc3-ba7901539c25","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\n\n\n# Load the image (Ensure path correctness)\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')  # Convert to grayscale\n\nimage = image.resize((224, 224))\n\nimage_np = np.array(image)\n\n\n\ndef getLBPimage(gray_image):\n\n    '''\n\n    == Input ==\n\n    gray_image  : grayscale image of shape (height, width)\n\n\n\n    == Output ==\n\n    imgLBP : LBP converted image of the same shape\n\n    '''\n\n    # Initialize LBP image with zeros\n\n    imgLBP = np.zeros_like(gray_image)\n\n    neighboor = 3  # Define a 3x3 neighborhood\n\n\n\n    # Iterate over each pixel (excluding borders)\n\n    for ih in range(1, gray_image.shape[0] - 1):\n\n        for iw in range(1, gray_image.shape[1] - 1):\n\n            # Step 1: Get the 3x3 neighborhood around the pixel\n\n            img = gray_image[ih-1:ih+2, iw-1:iw+2]  # 3x3 window\n\n            center = img[1, 1]  # The center pixel\n\n            # Step 2: Create a binary pattern by thresholding\n\n            img01 = (img >= center).astype(int)\n\n            # Step 3: Flatten the matrix into a vector (excluding the center)\n\n            img01_vector = np.delete(img01.flatten(), 4)\n\n            # Step 4: Convert the binary pattern to a decimal number\n\n            num = np.dot(img01_vector, 2 ** np.arange(8))\n\n            # Step 5: Assign this number to the LBP image\n\n            imgLBP[ih, iw] = num\n\n\n\n    return imgLBP\n\n\n\n# Apply LBP to the single image\n\nimgLBP = getLBPimage(image_np)\n\n\n\n# Flatten the LBP image for histogram\n\nvecimgLBP = imgLBP.flatten()\n\n\n\n# Plot the original image, LBP image, and histogram\n\nfig = plt.figure(figsize=(20, 8))\n\n\n\n# Plot original grayscale image\n\nax = fig.add_subplot(1, 3, 1)\n\nax.imshow(image_np, cmap=\"gray\")\n\nax.set_title(\"Grayscale Image\")\n\n\n\n# Plot LBP converted image\n\nax = fig.add_subplot(1, 3, 2)\n\nax.imshow(imgLBP, cmap=\"gray\")\n\nax.set_title(\"LBP Converted Image\")\n\n\n\n# Plot LBP histogram\n\nax = fig.add_subplot(1, 3, 3)\n\nfreq, lbp, _ = ax.hist(vecimgLBP, bins=256)\n\nax.set_ylim(0, 40000)\n\nlbp = lbp[:-1]\n\n\n\n# Print LBP values with high frequencies\n\nlargeTF = freq > 5000\n\nfor x, fr in zip(lbp[largeTF], freq[largeTF]):\n\n    ax.text(x, fr, \"{:6.0f}\".format(x), color=\"magenta\")\n\nax.set_title(\"LBP Histogram\")\n\n\n\nplt.show()\n","metadata":{"id":"_qG8MqkwJm77","colab":{"base_uri":"https://localhost:8080/","height":508},"outputId":"3bb3b291-3636-4933-e4f6-20a671e5bc02","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\n\n\n# Load the image (Ensure path correctness)\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')  # Convert to grayscale\n\nimage = image.resize((224, 224))\n\nimage_np = np.array(image)\n\n\n\ndef getLBPimageUsingMean(gray_image):\n\n    '''\n\n    == Input ==\n\n    gray_image  : grayscale image of shape (height, width)\n\n\n\n    == Output ==\n\n    imgLBP : LBP converted image of the same shape using mean value\n\n    '''\n\n    # Initialize LBP image with zeros\n\n    imgLBP = np.zeros_like(gray_image)\n\n    neighboor = 3  # Define a 3x3 neighborhood\n\n    # Iterate over each pixel (excluding borders)\n\n    for ih in range(1, gray_image.shape[0] - 1):\n\n        for iw in range(1, gray_image.shape[1] - 1):\n\n            # Step 1: Get the 3x3 neighborhood around the pixel\n\n            img = gray_image[ih-1:ih+2, iw-1:iw+2]  # 3x3 window\n\n            mean_value = np.mean(img)  # Calculate mean of the neighborhood\n\n            # Step 2: Create a binary pattern by thresholding with mean value\n\n            img01 = (img >= mean_value).astype(int)\n\n            # Step 3: Flatten the matrix into a vector (excluding the center)\n\n            img01_vector = np.delete(img01.flatten(), 4)\n\n            # Step 4: Convert the binary pattern to a decimal number\n\n            num = np.dot(img01_vector, 2 ** np.arange(8))\n\n            # Step 5: Assign this number to the LBP image\n\n            imgLBP[ih, iw] = num\n\n\n\n    return imgLBP\n\n\n\n# Apply LBP to the single image using mean value\n\nimgLBP = getLBPimageUsingMean(image_np)\n\n\n\n# Flatten the LBP image for histogram\n\nvecimgLBP = imgLBP.flatten()\n\n\n\n# Plot the original image, LBP image, and histogram\n\nfig = plt.figure(figsize=(20, 8))\n\n\n\n# Plot original grayscale image\n\nax = fig.add_subplot(1, 3, 1)\n\nax.imshow(image_np, cmap=\"gray\")\n\nax.set_title(\"Grayscale Image\")\n\n\n\n# Plot LBP converted image\n\nax = fig.add_subplot(1, 3, 2)\n\nax.imshow(imgLBP, cmap=\"gray\")\n\nax.set_title(\"Mean-based LBP Converted Image\")\n\n\n\n# Plot LBP histogram\n\nax = fig.add_subplot(1, 3, 3)\n\nfreq, lbp, _ = ax.hist(vecimgLBP, bins=256)\n\nax.set_ylim(0, 40000)\n\nlbp = lbp[:-1]\n\n\n\n# Print LBP values with high frequencies\n\nlargeTF = freq > 5000\n\nfor x, fr in zip(lbp[largeTF], freq[largeTF]):\n\n    ax.text(x, fr, \"{:6.0f}\".format(x), color=\"magenta\")\n\nax.set_title(\"LBP Histogram\")\n\n\n\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"AEV1QA3rrIPh","outputId":"df783bce-fffc-478b-9f2b-499704404e8b","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\n\n\n# Load the image (Ensure path correctness)\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')\n\nimage = image.resize((224, 224))\n\nimage_np = np.array(image)\n\n\n\ndef getLBPimageUsingMedian(gray_image):\n\n    '''\n\n    == Input ==\n\n    gray_image  : grayscale image of shape (height, width)\n\n\n\n    == Output ==\n\n    imgLBP : LBP converted image of the same shape using median value\n\n    '''\n\n    # Initialize LBP image with zeros\n\n    imgLBP = np.zeros_like(gray_image)\n\n    neighboor = 3  # Define a 3x3 neighborhood\n\n    # Iterate over each pixel (excluding borders)\n\n    for ih in range(1, gray_image.shape[0] - 1):\n\n        for iw in range(1, gray_image.shape[1] - 1):\n\n            # Step 1: Get the 3x3 neighborhood around the pixel\n\n            img = gray_image[ih-1:ih+2, iw-1:iw+2]  # 3x3 window\n\n            median_value = np.median  (img)  # Calculate median of the neighborhood\n\n            # Step 2: Create a binary pattern by thresholding with median value\n\n            img01 = (img >= median_value).astype(int)\n\n            # Step 3: Flatten the matrix into a vector (excluding the center)\n\n            img01_vector = np.delete(img01.flatten(), 4)\n\n            # Step 4: Convert the binary pattern to a decimal number\n\n            num = np.dot(img01_vector, 2 ** np.arange(8))\n\n            # Step 5: Assign this number to the LBP image\n\n            imgLBP[ih, iw] = num\n\n\n\n    return imgLBP\n\n\n\n# Apply LBP to the single image using median value\n\nimgLBP = getLBPimageUsingMedian(image_np)\n\n\n\n# Flatten the LBP image for histogram\n\nvecimgLBP = imgLBP.flatten()\n\n\n\n# Plot the original image, LBP image, and histogram\n\nfig = plt.figure(figsize=(20, 8))\n\n\n\n# Plot original grayscale image\n\nax = fig.add_subplot(1, 3, 1)\n\nax.imshow(image_np, cmap=\"gray\")\n\nax.set_title(\"Grayscale Image\")\n\n\n\n# Plot LBP converted image\n\nax = fig.add_subplot(1, 3, 2)\n\nax.imshow(imgLBP, cmap=\"gray\")\n\nax.set_title(\"Median-based LBP Converted Image\")\n\n\n\n# Plot LBP histogram\n\nax = fig.add_subplot(1, 3, 3)\n\nfreq, lbp, _ = ax.hist(vecimgLBP, bins=256)\n\nax.set_ylim(0, 40000)\n\nlbp = lbp[:-1]\n\n\n\n# Print LBP values with high frequencies\n\nlargeTF = freq > 5000\n\nfor x, fr in zip(lbp[largeTF], freq[largeTF]):\n\n    ax.text(x, fr, \"{:6.0f}\".format(x), color=\"magenta\")\n\nax.set_title(\"LBP Histogram\")\n\n\n\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":508},"id":"kE0MaxxvtxT5","outputId":"48841d37-2be4-4f24-ff11-e898a86ab3bf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\n\n\n# Load the image (Ensure path correctness)\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')\n\nimage = image.resize((224, 224))\n\nimage_np = np.array(image)\n\n\n\ndef getLBPimageUsingVariance(gray_image):\n\n    '''\n\n    == Input ==\n\n    gray_image  : grayscale image of shape (height, width)\n\n\n\n    == Output ==\n\n    imgLBP : LBP converted image of the same shape using variance\n\n    '''\n\n    # Initialize LBP image with zeros\n\n    imgLBP = np.zeros_like(gray_image)\n\n    neighboor = 3  # Define a 3x3 neighborhood\n\n    # Iterate over each pixel (excluding borders)\n\n    for ih in range(1, gray_image.shape[0] - 1):\n\n        for iw in range(1, gray_image.shape[1] - 1):\n\n            # Step 1: Get the 3x3 neighborhood around the pixel\n\n            img = gray_image[ih-1:ih+2, iw-1:iw+2]  # 3x3 window\n\n            variance_value = np.var(img)  # Calculate variance of the neighborhood\n\n            # Step 2: Create a binary pattern by thresholding with the variance\n\n            img01 = (img >= variance_value).astype(int)\n\n            # Step 3: Flatten the matrix into a vector (excluding the center)\n\n            img01_vector = np.delete(img01.flatten(), 4)\n\n            # Step 4: Convert the binary pattern to a decimal number\n\n            num = np.dot(img01_vector, 2 ** np.arange(8))\n\n            # Step 5: Assign this number to the LBP image\n\n            imgLBP[ih, iw] = num\n\n\n\n    return imgLBP\n\n\n\n# Apply LBP to the single image using variance\n\nimgLBP = getLBPimageUsingVariance(image_np)\n\n# Flatten the LBP image for histogram\n\nvecimgLBP = imgLBP.flatten()\n\n# Plot the original image, LBP image, and histogram\n\nfig = plt.figure(figsize=(20, 8))\n\n# Plot original grayscale image\n\nax = fig.add_subplot(1, 3, 1)\n\nax.imshow(image_np, cmap=\"gray\")\n\nax.set_title(\"Grayscale Image\")\n\n# Plot LBP converted image\n\nax = fig.add_subplot(1, 3, 2)\n\nax.imshow(imgLBP, cmap=\"gray\")\n\nax.set_title(\"Variance-based LBP Converted Image\")\n\n# Plot LBP histogram\n\nax = fig.add_subplot(1, 3, 3)\n\nfreq, lbp, _ = ax.hist(vecimgLBP, bins=256)\n\nax.set_ylim(0, 40000)\n\nlbp = lbp[:-1]\n\n# Print LBP values with high frequencies\n\nlargeTF = freq > 5000\n\nfor x, fr in zip(lbp[largeTF], freq[largeTF]):\n\n    ax.text(x, fr, \"{:6.0f}\".format(x), color=\"magenta\")\n\nax.set_title(\"LBP Histogram\")\n\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":573},"id":"EZ_qRQWSKoU2","outputId":"873febb0-7834-489e-b355-0489cc3e71e5","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\n\n\n# Load the image (Ensure path correctness)\n\nimage_path = '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg'\n\nimage = Image.open(image_path).convert('L')\n\nimage = image.resize((224, 224))\n\nimage_np = np.array(image)\n\n\n\ndef getLBPimageUsingMVM(gray_image):\n\n    '''\n\n    == Input ==\n\n    gray_image  : grayscale image of shape (height, width)\n\n\n\n    == Output ==\n\n    imgLBP : LBP converted image of the same shape using Mean-Variance-Median (MVM) metric\n\n    '''\n\n    # Initialize LBP image with zeros\n\n    imgLBP = np.zeros_like(gray_image)\n\n\n\n    # Iterate over each pixel (excluding borders)\n\n    for ih in range(1, gray_image.shape[0] - 1):\n\n        for iw in range(1, gray_image.shape[1] - 1):\n\n            # Step 1: Get the 3x3 neighborhood around the pixel\n\n            img = gray_image[ih-1:ih+2, iw-1:iw+2]  # 3x3 window\n\n            # Step 2: Calculate Mean, Variance, and Median of the neighborhood\n\n            mean_value = np.mean(img)\n\n            variance_value = np.var(img)\n\n            median_value = np.median(img)\n\n            # Step 3: Calculate MVM threshold\n\n            mvm_threshold = (mean_value + np.sqrt(variance_value) + median_value) / 3\n\n            # Step 4: Create a binary pattern by thresholding with MVM threshold\n\n            img01 = (img >= mvm_threshold).astype(int)\n\n            # Step 5: Flatten the matrix into a vector (excluding the center)\n\n            img01_vector = np.delete(img01.flatten(), 4)\n\n            # Step 6: Convert the binary pattern to a decimal number\n\n            num = np.dot(img01_vector, 2 ** np.arange(8))\n\n            # Step 7: Assign this number to the LBP image\n\n            imgLBP[ih, iw] = num\n\n    return imgLBP\n\n\n\n# Apply MVM-LBP to the single image\n\nimgLBP = getLBPimageUsingMVM(image_np)\n\n# Flatten the MVM-LBP image for histogram\n\nvecimgLBP = imgLBP.flatten()\n\n# Plot the original image, MVM-LBP image, and histogram\n\nfig = plt.figure(figsize=(20, 8))\n\n# Plot original grayscale image\n\nax = fig.add_subplot(1, 3, 1)\n\nax.imshow(image_np, cmap=\"gray\")\n\nax.set_title(\"Grayscale Image\")\n\n# Plot MVM-based LBP converted image\n\nax = fig.add_subplot(1, 3, 2)\n\nax.imshow(imgLBP, cmap=\"gray\")\n\nax.set_title(\"MVM-based LBP Converted Image\")\n\n# Plot MVM-LBP histogram\n\nax = fig.add_subplot(1, 3, 3)\n\nfreq, lbp, _ = ax.hist(vecimgLBP, bins=256)\n\nax.set_ylim(0, 40000)\n\nlbp = lbp[:-1]\n\n\n\n# Print MVM-LBP values with high frequencies\n\nlargeTF = freq > 5000\n\nfor x, fr in zip(lbp[largeTF], freq[largeTF]):\n\n    ax.text(x, fr, \"{:6.0f}\".format(x), color=\"magenta\")\n\nax.set_title(\"MVM-LBP Histogram\")\n\n\n\nplt.show()\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":592},"id":"UieG_JTTU1Xv","outputId":"e6f75a01-6a83-4e11-b298-fccb76464865","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\n\n\n\ndef getLBPimageUsingMVM(gray_image):\n\n    '''\n\n    == Input ==\n\n    gray_image  : grayscale image of shape (height, width)\n\n\n\n    == Output ==\n\n    imgLBP : LBP converted image of the same shape using Mean-Variance-Median (MVM) metric\n\n    '''\n\n    # Initialize LBP image with zeros\n\n    imgLBP = np.zeros_like(gray_image)\n\n\n\n    # Iterate over each pixel (excluding borders)\n\n    for ih in range(1, gray_image.shape[0] - 1):\n\n        for iw in range(1, gray_image.shape[1] - 1):\n\n            # Step 1: Get the 3x3 neighborhood around the pixel\n\n            img = gray_image[ih-1:ih+2, iw-1:iw+2]  # 3x3 window\n\n            # Step 2: Calculate Mean, Variance, and Median of the neighborhood\n\n            mean_value = np.mean(img)\n\n            variance_value = np.var(img)\n\n            median_value = np.median(img)\n\n            # Step 3: Calculate MVM threshold\n\n            mvm_threshold = (mean_value + np.sqrt(variance_value) + median_value) / 3\n\n            # Step 4: Create a binary pattern by thresholding with MVM threshold\n\n            img01 = (img >= mvm_threshold).astype(int)\n\n            # Step 5: Flatten the matrix into a vector (excluding the center)\n\n            img01_vector = np.delete(img01.flatten(), 4)\n\n            # Step 6: Convert the binary pattern to a decimal number\n\n            num = np.dot(img01_vector, 2 ** np.arange(8))\n\n            # Step 7: Assign this number to the LBP image\n\n            imgLBP[ih, iw] = num\n\n    return imgLBP\n\n\n\n# List of image paths\n\nimage_paths = [\n\n    '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2127/SUB7/p-049.jpg',\n\n    '/kaggle/input/infosys-mri-dataset/train/Benign/BreaDM-Be-1805/SUB1/p-025.jpg',\n\n    '/kaggle/input/infosys-mri-dataset/train/Benign/BreaDM-Be-1805/VIBRANT+C1/p-029.jpg',\n\n    '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2117/SUB5/p-085.jpg',\n\n    '/kaggle/input/infosys-mri-dataset/train/Malignant/BreaDM-Ma-2128/SUB8/p-052.jpg' ]\n\n\n\n# Create a figure for plotting\n\nfig, axs = plt.subplots(len(image_paths), 3, figsize=(20, 4 * len(image_paths)))\n\n\n\n# Process each image\n\nfor idx, image_path in enumerate(image_paths):\n\n    # Load and preprocess the image\n\n    image = Image.open(image_path).convert('L')\n\n    image = image.resize((224, 224))\n\n    image_np = np.array(image)\n\n\n\n    # Apply MVM-LBP to the single image\n\n    imgLBP = getLBPimageUsingMVM(image_np)\n\n    # Flatten the MVM-LBP image for histogram\n\n    vecimgLBP = imgLBP.flatten()\n\n\n\n    # Plot original grayscale image\n\n    axs[idx, 0].imshow(image_np, cmap=\"gray\")\n\n    axs[idx, 0].set_title(f\"Grayscale Image {idx + 1}\")\n\n    axs[idx, 0].axis('off')\n\n\n\n    # Plot MVM-based LBP converted image\n\n    axs[idx, 1].imshow(imgLBP, cmap=\"gray\")\n\n    axs[idx, 1].set_title(f\"MVM-based LBP Image {idx + 1}\")\n\n    axs[idx, 1].axis('off')\n\n\n\n    # Plot MVM-LBP histogram\n\n    freq, lbp, _ = axs[idx, 2].hist(vecimgLBP, bins=256, color='black', alpha=0.7)\n\n    axs[idx, 2].set_ylim(0, 40000)\n\n    lbp = lbp[:-1]\n\n\n\n    # Print MVM-LBP values with high frequencies\n\n    largeTF = freq > 5000\n\n    for x, fr in zip(lbp[largeTF], freq[largeTF]):\n\n        axs[idx, 2].text(x, fr, \"{:6.0f}\".format(x), color=\"magenta\")\n\n\n\n    axs[idx, 2].set_title(f\"MVM-LBP Histogram {idx + 1}\")\n\n    axs[idx, 2].set_xlabel(\"MVM-LBP Value\")\n\n    axs[idx, 2].set_ylabel(\"Frequency\")\n\n\n\nplt.tight_layout()\n\nplt.show()\n","metadata":{"id":"8nC_XDprX_v-","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"02de173d-0244-40a3-de68-dcd059852028","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#gclm code for 5 pictures","metadata":{"id":"GqtPnUyeolzN","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nfrom torchvision import datasets, transforms\n\nfrom torch.utils.data import DataLoader, Subset\n\nimport numpy as np\n\n\n\n# Path to the dataset in Google Drive\n\ndata_dir = '/kaggle/input/infosys-mri-dataset'\n\n\n\n# Define transformations for your dataset\n\ndata_transforms = {\n\n    'train': transforms.Compose([\n\n        transforms.Resize((224, 224)),\n\n        transforms.ToTensor(),\n\n    ]),\n\n    'val': transforms.Compose([\n\n        transforms.Resize((224, 224)),\n\n        transforms.ToTensor(),\n\n    ]),\n\n    'test': transforms.Compose([\n\n        transforms.Resize((224, 224)),\n\n        transforms.ToTensor(),\n\n    ]),\n\n}\n\n\n\n# Load labeled dataset (organized in class subdirectories)\n\nlabeled_data_dir = os.path.join(data_dir, 'train')\n\nlabeled_dataset = datasets.ImageFolder(labeled_data_dir, transform=data_transforms['train'])\n\n\n\n# Extract indices for labeled data\n\nlabeled_indices = np.arange(len(labeled_dataset))\n\nX_labeled = Subset(labeled_dataset, labeled_indices)  # Features (X) for labeled\n\ny_labeled = [labeled_dataset.targets[i] for i in labeled_indices]  # Labels (y) for labeled\n\n\n\n# Load unlabeled dataset if it's in a separate folder (no class subfolders)\n\nunlabeled_data_dir = os.path.join(data_dir, 'unlabeled')\n\nif os.path.exists(unlabeled_data_dir):\n\n    unlabeled_dataset = datasets.ImageFolder(unlabeled_data_dir, transform=data_transforms['train'])\n\n    # All images in this dataset are treated as unlabeled\n\n    X_unlabeled = DataLoader(unlabeled_dataset, batch_size=32, shuffle=True)\n\nelse:\n\n    print(\"Unlabeled dataset directory not found.\")\n\n\n\n# Create data loaders for labeled and unlabeled\n\ntrain_loader = DataLoader(X_labeled, batch_size=32, shuffle=True)\n\nval_loader = DataLoader(datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=data_transforms['val']),\n\n                        batch_size=32, shuffle=True)\n\ntest_loader = DataLoader(datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=data_transforms['test']),\n\n                         batch_size=32, shuffle=False)\n\n\n\n# Store all loaders in a dictionary for easier access\n\ndataloaders = {\n\n    'train': train_loader,\n\n    'val': val_loader,\n\n    'test': test_loader,\n\n    'unlabeled': X_unlabeled if 'X_unlabeled' in locals() else None  # Check if unlabeled data exists\n\n}\n\n\n\nprint(\"Labeled and unlabeled data loaders created successfully.\")\n","metadata":{"id":"2Uo3oJko3hxf","colab":{"base_uri":"https://localhost:8080/"},"outputId":"130cc5c6-ac5d-4fb7-d64b-faef99785f57","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nimport torchvision.models as models\n# Load the VGG-16 model pre-trained on ImageNet\nvgg16 = models.vgg16(pretrained=True)\n# Set the model to evaluation mode\n\nvgg16.eval()","metadata":{"id":"RlxSDtCXQ8hL","colab":{"base_uri":"https://localhost:8080/"},"outputId":"daa80ccc-5017-4c99-a8be-aeb81757e3b6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n\n\nimport torchvision.models as models\n\n\n\nvgg16 = models.vgg16(pretrained=True)\n\n\n\nvgg16.eval()\n\n\n\nprint(vgg16)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\n\n# For ResNet18\nresnet18 = models.resnet18(pretrained=True)\nresnet18.eval()  # Set the model to evaluation mode\nprint(\"ResNet18 Model:\")\nprint(resnet18)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nimport torch.nn as nn\n\nimport torchvision.models as models\n\nclass Resnet18(nn.Module):\n    def __init__(self, num_classes=2):\n        super(Resnet18, self).__init__()\n        model_resnet18 = models.resnet18(pretrained=True)\n        self.conv1 = model_resnet18.conv1  # convolutional function\n        self.bn1 = model_resnet18.bn1  # batch normalization\n        self.relu = model_resnet18.relu  # relu is your activation function.\n        self.maxpool = model_resnet18.maxpool  # maxpool is basically taking the biggest value per\n        \n        # sub_matrix\n        self.layer1 = model_resnet18.layer1\n        self.layer2 = model_resnet18.layer2\n        self.layer3 = model_resnet18.layer3\n        self.layer4 = model_resnet18.layer4  # these layers are used for deepening the layers in the architecture which will increase\n        \n        self.avgpool = model_resnet18.avgpool\n        self.features = model_resnet18.fc.in_features\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc = nn.Linear(self.features, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Resnet18()\n\nprint(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Resnet50(nn.Module):\n    def __init__(self, num_classes=2):\n        super(Resnet50, self).__init__()\n        model_resnet50 = models.resnet50(pretrained=True)\n        self.conv1 = model_resnet50.conv1\n        self.bn1 = model_resnet50.bn1\n        self.relu = model_resnet50.relu\n        self.maxpool = model_resnet50.maxpool\n        self.layer1 = model_resnet50.layer1\n        self.layer2 = model_resnet50.layer2\n        self.layer3 = model_resnet50.layer3\n        self.layer4 = model_resnet50.layer4\n        self.avgpool = model_resnet50.avgpool\n        self.features = model_resnet50.fc.in_features\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc = nn.Linear(self.features, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nimport torch.nn as nn\n\nimport torchvision.models as models\n\n\n\nclass customVGG16(nn.Module):\n\n    def __init__(self, num_classes=2):\n\n        super(customVGG16, self).__init__()\n\n\n\n        # Load the pre-trained VGG16 model\n\n        vgg16 = models.vgg16(pretrained=True)\n\n\n\n        # Extract features and avgpool layers\n\n        self.features = vgg16.features\n\n        self.avgpool = vgg16.avgpool\n\n\n\n        # Define a new classifier\n\n        self.classifier = nn.Sequential(\n\n            nn.Linear(512 * 7 * 7, 4096),  # Linear layer with input size 512 7 7 and output size 4096\n\n            nn.ReLU(),                    # ReLU activation function\n\n            nn.Dropout(p=0.5),                 # Dropout\n\n            nn.Linear(4096, 4096),         # Another linear layer with input size 4096 and output size 4096\n\n            nn.ReLU(),                    # ReLU activation\n\n            nn.Dropout(),                 # Dropout layer\n\n            nn.Linear(4096, num_classes)  # Final Linear layer with output size equal to number of classes\n\n        )\n\n\n\n    # Forward Method (Make sure this is outside the __init__ method)\n\n    def forward(self, x):\n\n        # Pass input through the features layer\n\n        x = self.features(x)\n\n        # Pass through the AVGpool layer\n\n        x = self.avgpool(x)\n\n        # Reshape output to a 2D tensor\n\n        x = torch.flatten(x, 1)\n\n        # Pass through the classifier\n\n        x = self.classifier(x)\n\n\n\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = customVGG16()\n\nprint(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\n\nimport torch\n\n\n\nclass EarlyStopping:\n\n    def __init__(self, patience=12, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n\n\n\n        self.patience = patience\n\n        self.verbose = verbose\n\n        self.delta = delta\n\n        self.path = path\n\n        self.trace_func = trace_func\n\n\n\n        self.counter = 0\n\n        self.best_score = None\n\n        self.early_stop = False\n\n        self.val_loss_min = np.Inf\n\n\n\n    def __call__(self, val_loss, model):\n\n        score = -val_loss\n\n\n\n        # Initialize best_score if not set, and check for improvement\n\n        if self.best_score is None:\n\n            self.best_score = score\n\n            self.save_checkpoint(val_loss, model)\n\n        elif score < self.best_score + self.delta:\n\n            self.counter += 1\n\n            if self.verbose:\n\n                self.trace_func(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n\n            if self.counter >= self.patience:\n\n                self.early_stop = True\n\n        else:\n\n            self.best_score = score\n\n            self.save_checkpoint(val_loss, model)\n\n            self.counter = 0\n\n\n\n    def save_checkpoint(self, val_loss, model):\n\n        \"\"\"Saves model when validation loss decreases.\"\"\"\n\n        if self.verbose:\n\n            self.trace_func(f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}). Saving model...\")\n\n        torch.save(model.state_dict(), self.path)\n\n        self.val_loss_min = val_loss\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n\n\nimport torch.nn.functional as F\n\n\n\nfrom tqdm import tqdm\n\n\n\nimport torch.optim as optim\n\n\n\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#no_cuda = not torch.cuda.is_available()  # Set to True if CUDA is not available\n\n#device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n\n#print(f\"Using device: {device}\")\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = model.to(device)\n\n\n\n#device = torch.device(\"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\n#from tqdm import tqdm #already imported in previous cell\nimport torch.optim as optim\n#from tqdm import tqdm  #already imported in previous cell\n\n# Get the CPU device\n\n#device = torch.device(\"cpu\")\n\n#print(f\"Using device: {device}\")\n\n# ... rest of your code using 'device' for tensors ...","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\nimport torch.nn.functional as F\n\nepoch = 0\n\ntotal_epochs = 50\n\nloader = train_loader  # Ensure this is a DataLoader instance for training data\n\ncriterion = nn.CrossEntropyLoss()\n\nl2_decay = 0.001\n\nlr = 0.001  # Learning rate\n\n\n\ndef train(epoch, model, num_epochs, loader, criterion, l2_decay):\n\n    learing_rate = max(lr*(0.1**(epoch//10)),1e-5)\n    optimizer = torch.optim.SGD(model.parameters(), lr= learing_rate, momentum=0.9, weight_decay=l2_decay)\n\n    model.train()\n\n    correct = 0\n    for data, label in tqdm(loader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch'):\n        data = data.float().cuda()\n\n        label = label.long().cuda()\n\n        output = model(data)\n        optimizer.zero_grad()\n        loss = F.nll_loss(F.log_softmax(output, dim=1), label)\n        loss.backward()\n        optimizer.step()\n\n        pred = output.data.max(1)[1]\n        correct += pred.eq(label.data.view_as(pred)).cpu().sum()\n\n    print(f'train accuracy: {100. * correct / len(loader.dataset)}%')\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc as compute_auc  # Rename the imported 'auc' function\nimport sklearn.metrics as metrics\n\ndef validation(model, val_loader):\n    model.eval()  # Set model to evaluation mode\n    test_loss = 0\n    correct = 0\n    all_predictions = []  # Store all predictions\n    all_targets = []  # Store all targets\n    possibilities = None  # Store probabilities for AUC\n\n    for data, target in val_loader:\n        if torch.cuda.is_available():\n            data, target = data.cuda(), target.cuda()\n\n        val_output = model(data)\n\n        # Calculate test loss\n        test_loss += F.nll_loss(F.log_softmax(val_output, dim=1), target, reduction='sum').item()\n\n        # Get predictions and accumulate them\n        pred = val_output.data.max(1)[1]\n        all_predictions.extend(pred.cpu().numpy())  # Collect all predictions\n        all_targets.extend(target.cpu().numpy())  # Collect all target labels\n\n        # Calculate probabilities for AUC\n        possibility = F.softmax(val_output, dim=1).cpu().detach().numpy()\n        if possibilities is None:\n            possibilities = possibility\n        else:\n            possibilities = np.concatenate((possibilities, possibility), axis=0)\n\n        # Calculate the number of correct predictions\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    # Compute confusion matrix\n    cm = metrics.confusion_matrix(all_targets, all_predictions)\n\n    # One-hot encode the labels for AUC computation\n    num_classes = val_output.shape[1]\n    label_onehot = np.eye(num_classes)[np.array(all_targets).astype(int)]\n\n    # Compute ROC curve and AUC\n    fpr, tpr, thresholds = roc_curve(label_onehot.ravel(), possibilities.ravel())\n    auc_score = compute_auc(fpr, tpr)  # Use 'compute_auc' to avoid conflicts\n\n    # Average test loss per sample\n    test_loss /= len(val_loader.dataset)\n\n    # Calculate specificity and sensitivity\n    specificity = 1 - fpr[1] if len(fpr) > 1 else 0\n    sensitivity = tpr[1] if len(tpr) > 1 else 0\n\n    print('Specificity: {:.4f}, Sensitivity: {:.4f}, AUC: {:.4f}'.format(specificity, sensitivity, auc_score))\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {:.2f}%\\n'.format(test_loss, 100. * correct / len(val_loader.dataset)))\n\n    return test_loss, 100. * correct / len(val_loader.dataset), cm, auc_score\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_epochs = 50\n\nlr = 0.0001\n\nmomentum = 0.9\n\nno_cuda = False\n\nnum_classes=2\n\nlog_interval = 10\n\nl2_decay = 0.001\n\nmodel = customVGG16(num_classes=num_classes)\n\nmodel = model.to(device)\n\n\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nfrom IPython.display import FileLink\n\n# Model training\nmodel.to(device)  \n\nbest_accuracy = 0\nearly_stop = EarlyStopping(patience=12, verbose=True)\n\nproject_name = 'tumor_classification'\nmodel_name = 'vgg16'\n\n# Set Kaggle working directory\nos.chdir(r'/kaggle/working')\n\nfor epoch in range(1, total_epochs + 1):\n    # Training step\n    train(epoch, model, total_epochs, train_loader, criterion, l2_decay)\n\n    # Validation step\n    with torch.no_grad():\n        test_loss, accuracy, cm, auc = validation(model, val_loader)\n\n    # Handle model state for single/multiple GPUs\n    model_state_dict = model.module.state_dict() if isinstance(model, nn.parallel.DistributedDataParallel) else model.state_dict()\n\n    # Save directory for models\n    model_save_dir = os.path.join('model', project_name, model_name)\n    if not os.path.exists(model_save_dir):\n        os.makedirs(model_save_dir)\n\n    # Early stopping check\n    early_stop(test_loss, model)\n\n    # Save the best model\n    if auc > best_accuracy:\n        best_accuracy = auc\n        model_save_path = os.path.join(model_save_dir, f'{model_name}_epoch_{epoch}.pth')\n        torch.save(model_state_dict, model_save_path, _use_new_zipfile_serialization=False)\n        print(f\"Model saved at: {os.path.abspath(model_save_path)}\")\n\n        # Generate download link for Kaggle\n        print(\"Generating download link for the saved model...\")\n        display(FileLink(model_save_path))\n\n    # Stop training if early stopping is triggered\n    if early_stop.early_stop:\n        print(\"Early stopping\")\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport torch\n\nimport numpy as np\n\nimport torch.nn.functional as F\n\n\n\ndef test(model, test_loader):\n    \n    name = 'test'\n\n    len_test_loader = len(test_loader.dataset)\n\n    model.eval()\n\n\n\n    test_loss = 0\n\n    correct = 0\n\n    possibilities = None\n\n    all_predictions = []\n\n    labels = ['benign', 'malignant']\n\n\n\n    for data, target in test_loader:\n\n        if torch.cuda.is_available():\n\n            data, target = data.cuda(), target.cuda()\n\n\n\n        test_output = model(data)\n\n        test_loss += F.nll_loss(F.log_softmax(test_output, dim=1), target, reduction='sum').item()\n\n\n\n        pred = test_output.data.max(1)[1]\n\n        all_predictions.append(pred.cpu().numpy())\n\n\n\n        possibility = F.softmax(test_output, dim=1).cpu().data.numpy()\n\n        if possibilities is None:\n\n            possibilities = possibility\n\n        else:\n\n            possibilities = np.concatenate((possibilities, possibility), axis=0)\n\n\n\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n\n\n    all_predictions = [i for item in all_predictions for i in item]\n\n\n\n    # classification metrics -> accuracy, f1 score\n\n    print(metrics.classification_report(labels, all_predictions, labels=range(2), target_names=labels, digits=4))\n\n    # confusion matrix\n\n    cm = metrics.confusion_matrix(labels, all_predictions, labels=range(2))\n\n\n\n    num_classes = test_output.shape[1]\n\n    label_onehot = np.eye(num_classes)[np.array(labels).astype(int).tolist()]\n\n\n\n    fpr, tpr, thresholds = roc_curve(label_onehot.ravel(), possibilities.ravel())\n\n    auc_value = roc_auc_score(label_onehot, possibilities, average=\"macro\")\n\n\n\n    test_loss /= len_test_dataloader\n\n    print('Specificity: {:.4f}, Sensitivity: {:.4f}, AUC: {:.4f}'.format(1 - fpr[0], tpr[0], auc_value))\n\n    print('\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n\n        name, test_loss, correct, len_test_dataloader,\n\n        100. * correct / len_test_dataloader))\n\n\n\n    return 100. * correct / len_test_dataloader, test_loss, auc_value\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\n\n# Testing setup\nmodel.eval()\nlen_test_loader = len(test_loader.dataset)\n\ntest_loss = 0\ncorrect = 0\npossibilities = None\nall_predictions = []\ntrue_labels = []\n\n# Iterate through the test data\nfor data, target in test_loader:\n    if torch.cuda.is_available():\n        data, target = data.cuda(), target.cuda()\n\n    # Forward pass\n    test_output = model(data)\n    test_loss += F.nll_loss(F.log_softmax(test_output, dim=1), target, reduction='sum').item()\n\n    # Get predictions and true labels\n    pred = test_output.data.max(1)[1]\n    all_predictions.extend(pred.cpu().numpy())\n    true_labels.extend(target.cpu().numpy())\n\n    # Store probabilities\n    possibility = F.softmax(test_output, dim=1).cpu().data.numpy()\n    if possibilities is None:\n        possibilities = possibility\n    else:\n        possibilities = np.concatenate((possibilities, possibility), axis=0)\n\n    # Calculate correct predictions\n    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n# Calculate test loss and accuracy\ntest_loss /= len_test_loader\naccuracy = 100. * correct / len_test_loader\n\n# Classification Report\nclass_names = ['benign', 'malignant']\nprint(metrics.classification_report(true_labels, all_predictions, target_names=class_names, digits=4))\n\n# Confusion Matrix\ncm = metrics.confusion_matrix(true_labels, all_predictions)\nprint(\"\\nConfusion Matrix:\\n\", cm)\n\n# ROC Curve and AUC\nnum_classes = len(class_names)\nlabel_onehot = np.eye(num_classes)[np.array(true_labels).astype(int).tolist()]\nfpr, tpr, thresholds = roc_curve(label_onehot.ravel(), possibilities.ravel())\nauc_value = roc_auc_score(label_onehot, possibilities, average=\"macro\")\n\n# Print Specificity, Sensitivity, and AUC\nprint('Specificity: {:.4f}, Sensitivity: {:.4f}, AUC: {:.4f}'.format(1 - fpr[0], tpr[0], auc_value))\n\n# Print Final Results\nprint('\\nTest Set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n    test_loss, correct, len_test_loader, accuracy))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"RESNET 18","metadata":{}},{"cell_type":"code","source":"# Define the device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n\n# Instantiate the model\nmodel = Resnet18(num_classes=num_classes)\nmodel = model.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\ntotal_epochs = 50\nlr = 0.0001\nmomentum = 0.9\nno_cuda = False\nnum_classes=2\nlog_interval = 10\nl2_decay = 0.001\nmodel = Resnet18(num_classes=num_classes)\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model training\nmodel.to(device)  # here device is cuda\nbest_accuracy = 0\nearly_stop = EarlyStopping(patience=12, verbose=True)\nproject_name = 'tumor_classfication'\nmodel_name = 'resnet18'\n\n# we will be using epochs. epochs will be defined in another code block.\n\nfor epoch in range(1, total_epochs + 1):\n\n      #train(epoch, model)#train(epoch, total_epochs, train_loader, criterion, l2_decay, lr)\n\n    train(epoch, model, total_epochs, train_loader, criterion, l2_decay)\n\n\n\n    with torch.no_grad():\n\n\n\n        #test_loss, auc = validation(model , val_loader)\n        test_loss, accuracy, cm, auc = validation(model, val_loader)\n\n\n\n\n    # making sure that the model can run on multiple GPUs\n\n\n\n    dict = model.module.state_dict() if isinstance(model, nn.parallel.DistributedDataParallel) else model.state_dict()\n\n\n\n    model_save_dir = os.path.join('model', project_name, model_name)\n\n\n\n    if not os.path.exists(model_save_dir):\n\n        os.makedirs(model_save_dir)\n\n\n\n    early_stop(test_loss, model)\n\n\n\n    if auc > best_accuracy:\n\n        best_accuracy = auc\n\n        #torch.save(os.path.join(model_save_dir, f'{model_name}_{epoch}.pth'), _use_new_zipfile_serialization=False)\n        torch.save(dict, os.path.join(model_save_dir, f'{model_name}_{epoch}.pth'), _use_new_zipfile_serialization=False)\n\n\n\n\n    if early_stop.early_stop:\n\n        print(\"Early stopping\")\n\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torchvision.models as models\n\n# For ResNet18\nresnet50 = models.resnet50(pretrained=True)\nresnet50.eval()  # Set the model to evaluation mode\nprint(\"ResNet50 Model:\")\nprint(resnet50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\nimport torch.nn as nn\n\nimport torchvision.models as models","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Resnet50(nn.Module):\n    def __init__(self, num_classes=2):\n        super(Resnet50, self).__init__()\n        model_resnet50 = models.resnet50(pretrained=True)\n        self.conv1 = model_resnet50.conv1\n        self.bn1 = model_resnet50.bn1\n        self.relu = model_resnet50.relu\n        self.maxpool = model_resnet50.maxpool\n        self.layer1 = model_resnet50.layer1\n        self.layer2 = model_resnet50.layer2\n        self.layer3 = model_resnet50.layer3\n        self.layer4 = model_resnet50.layer4\n        self.avgpool = model_resnet50.avgpool\n        self.features = model_resnet50.fc.in_features\n        self.dropout = nn.Dropout(p=0.5)\n        self.fc = nn.Linear(self.features, num_classes)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Resnet50()\n\nprint(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\ntotal_epochs = 50\nlr = 0.0001\nmomentum = 0.9\nno_cuda = False\nnum_classes=2\nlog_interval = 10\nl2_decay = 0.001\n#model = customVGG16(num_classes=num_classes)\nmodel = Resnet50(num_classes=num_classes)\nmodel = model.to(device)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model training\nmodel.to(device)  # here device is cuda\nbest_accuracy = 0\nearly_stop = EarlyStopping(patience=12, verbose=True)\nproject_name = 'tumor_classfication'\nmodel_name = 'resnet50'\n# we will be using epochs. epochs will be defined in another code block.\nfor epoch in range(1, total_epochs + 1):\n\n      #train(epoch, model)#train(epoch, total_epochs, train_loader, criterion, l2_decay, lr)\n\n    train(epoch, model, total_epochs, train_loader, criterion, l2_decay)\n\n\n\n    with torch.no_grad():\n\n\n\n        #test_loss, auc = validation(model , val_loader)\n        test_loss, accuracy, cm, auc = validation(model, val_loader)\n\n\n\n\n    # making sure that the model can run on multiple GPUs\n\n\n\n    dict = model.module.state_dict() if isinstance(model, nn.parallel.DistributedDataParallel) else model.state_dict()\n\n\n\n    model_save_dir = os.path.join('model', project_name, model_name)\n\n\n\n    if not os.path.exists(model_save_dir):\n\n        os.makedirs(model_save_dir)\n\n\n\n    early_stop(test_loss, model)\n\n\n\n    if auc > best_accuracy:\n\n        best_accuracy = auc\n\n        #torch.save(os.path.join(model_save_dir, f'{model_name}_{epoch}.pth'), _use_new_zipfile_serialization=False)\n        torch.save(dict, os.path.join(model_save_dir, f'{model_name}_{epoch}.pth'), _use_new_zipfile_serialization=False)\n        print(f'{model_name}_{epoch}')\n\n\n\n\n    if early_stop.early_stop:\n\n        print(\"Early stopping\")\n\n        break\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn import metrics\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\nimport torch\n\nimport numpy as np\n\nimport torch.nn.functional as F\n\n\n\ndef test(model, test_loader):\n\n    name = 'test'\n\n    len_test_loader = len(test_loader.dataset)\n\n    model.eval()\n\n\n\n    test_loss = 0\n\n    correct = 0\n\n    possibilities = None\n\n    all_predictions = []\n\n    labels = ['benign', 'malignant']\n\n\n\n    for data, target in test_loader:\n\n        if torch.cuda.is_available():\n\n            data, target = data.cuda(), target.cuda()\n\n\n\n        test_output = model(data)\n\n        test_loss += F.nll_loss(F.log_softmax(test_output, dim=1), target, reduction='sum').item()\n\n\n\n        pred = test_output.data.max(1)[1]\n\n        all_predictions.append(pred.cpu().numpy())\n\n\n\n        possibility = F.softmax(test_output, dim=1).cpu().data.numpy()\n\n        if possibilities is None:\n\n            possibilities = possibility\n\n        else:\n\n            possibilities = np.concatenate((possibilities, possibility), axis=0)\n\n\n\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n\n\n    all_predictions = [i for item in all_predictions for i in item]\n\n\n\n    # classification metrics -> accuracy, f1 score\n\n    print(metrics.classification_report(labels, all_predictions, labels=range(2), target_names=labels, digits=4))\n\n    # confusion matrix\n\n    cm = metrics.confusion_matrix(labels, all_predictions, labels=range(2))\n\n\n\n    num_classes = test_output.shape[1]\n\n    label_onehot = np.eye(num_classes)[np.array(labels).astype(int).tolist()]\n\n\n\n    fpr, tpr, thresholds = roc_curve(label_onehot.ravel(), possibilities.ravel())\n\n    auc_value = roc_auc_score(label_onehot, possibilities, average=\"macro\")\n\n\n\n    test_loss /= len_test_loader\n\n    print('Specificity: {:.4f}, Sensitivity: {:.4f}, AUC: {:.4f}'.format(1 - fpr[0], tpr[0], auc_value))\n\n    print('\\n{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n\n        name, test_loss, correct, len_test_loader,\n\n        100. * correct / len_test_loader))\n\n\n\n    return 100. * correct / len_test_loader, test_loss, auc_value\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\nimport torch\nimport numpy as np\nimport torch.nn.functional as F\n\ndef test(model, test_loader):\n    \"\"\"\n    Evaluate the model on a test dataset and calculate classification metrics.\n\n    Args:\n    - model (torch.nn.Module): The trained model.\n    - test_loader (torch.utils.data.DataLoader): DataLoader for the test dataset.\n\n    Returns:\n    - accuracy (float): Test accuracy in percentage.\n    - test_loss (float): Average loss on the test set.\n    - auc_value (float): Area under the ROC curve.\n    \"\"\"\n    model.eval()\n    len_test_loader = len(test_loader.dataset)\n\n    test_loss = 0\n    correct = 0\n    all_targets = []\n    all_predictions = []\n    possibilities = None\n\n    for data, target in test_loader:\n        if torch.cuda.is_available():\n            data, target = data.cuda(), target.cuda()\n\n        # Forward pass\n        test_output = model(data)\n        \n        # Compute loss\n        test_loss += F.nll_loss(F.log_softmax(test_output, dim=1), target, reduction='sum').item()\n\n        # Predictions\n        pred = test_output.data.max(1)[1]\n        all_predictions.extend(pred.cpu().numpy())\n        all_targets.extend(target.cpu().numpy())\n\n        # Probabilities\n        possibility = F.softmax(test_output, dim=1).cpu().data.numpy()\n        if possibilities is None:\n            possibilities = possibility\n        else:\n            possibilities = np.concatenate((possibilities, possibility), axis=0)\n\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    # Flatten lists for metric computation\n    all_predictions = np.array(all_predictions)\n    all_targets = np.array(all_targets)\n\n    # Classification metrics\n    print(\"\\nClassification Report:\")\n    print(classification_report(all_targets, all_predictions, target_names=['benign', 'malignant'], digits=4))\n\n    # Confusion matrix\n    print(\"\\nConfusion Matrix:\")\n    cm = confusion_matrix(all_targets, all_predictions)\n    print(cm)\n\n    # ROC and AUC\n    fpr, tpr, thresholds = roc_curve(all_targets, possibilities[:, 1])  # Use the positive class probabilities\n    auc_value = roc_auc_score(all_targets, possibilities[:, 1])\n\n    # Specificity and Sensitivity\n    specificity = 1 - fpr[1]  # Specificity = 1 - FPR\n    sensitivity = tpr[1]      # Sensitivity = TPR\n\n    # Average loss and accuracy\n    test_loss /= len_test_loader\n    accuracy = 100. * correct / len_test_loader\n\n    print('\\nSpecificity: {:.4f}, Sensitivity: {:.4f}, AUC: {:.4f}'.format(specificity, sensitivity, auc_value))\n    print('{} set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n        \"Test\", test_loss, correct, len_test_loader, accuracy))\n\n    return accuracy, test_loss, auc_value\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"accuracy, test_loss, auc_value = test(model, test_loader)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}